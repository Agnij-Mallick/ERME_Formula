\documentclass[openany,b5paper]{article}

%-----------------Preamble-----------------
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{pgfplots}

%-----------------Title-----------------
\title{Empirical Research in Management and Economics\\Formula Sheet}

%-----------------Document-----------------
\begin{document}
\maketitle

\section{Descriptive Statistics}
\subsection{Measure of Location}
\subsubsection{Mean}
\begin{align}
\bar{x} = \dfrac{1}{n} \displaystyle\sum_{i=1}^{n} x_i
\end{align}
\subsubsection{Median}
For odd number of elements in a dataset:
\begin{align}
\tilde{x} = x_{\frac{n+1}{2}}
\end{align}
For even number of elements in a dataset:
\begin{align}
\tilde{x} = \dfrac{x_{\frac{n}{2}}+x_{\left(\frac{n}{2}+1\right)}}{2}
\end{align}
\subsubsection{Mode}
\begin{align}
Mo(x) = \max(f(x_i))
\end{align}

\subsubsection{Quartile}
Measure of percentage of elements less than or equal to a term

\subsection{Measure of Spread}
\subsubsection{Variance}
Variance measured on the whole population
\begin{align}
\sigma^2 = \dfrac{1}{n} \sum_{i=1}^{n} \left( x_i - \bar{x} \right)^2
\end{align}
\subsubsection{Sample Variance}
Variance measured on a sample population
\begin{align}
s^2 = \dfrac{1}{n-1} \sum_{i=1}^{n} \left( x_i - \bar{x} \right)^2
\end{align}

\subsubsection{Standard Deviation and Sample Standard}
\begin{align}
\sigma = \sqrt{\sigma^2}\\
s=\sqrt{s^2}
\end{align}

\subsubsection{Co-efficient of Variance}
\begin{align}
v = \dfrac{s}{\bar{x}}
\end{align}

\subsection{Skewness}
\subsubsection{Types of Skewness}
\begin{table}[h!]
\begin{tabular}{c|c|c}
Name & Other Name & Characteristic\\
\hline
Right Skew & Positive Skew & Data concentrated on the lower side\\
Symmetric Distribution & Normal Distribution & Data distributed evenly\\
Left Skew & Negative Skew & Data concentrated on the higher side
\end{tabular}
\end{table}

\subsubsection{Measure of Skewness}
Skewness is measured by the Moment Co-efficient of Skewness.
\begin{align}
g_m &= \dfrac{m_3}{s^3}, \text{ where}\\
m_3 &= \dfrac{1}{n}\sum_{i=1}^{n} \left( x_i - \bar{x} \right)^3
\end{align}

\paragraph{Type of Skewness}
The type of skewness from the value is $g_m$ is:
\begin{table}[h!]
\begin{tabular}{c|c}
Value of $g_m$ & Type\\
\hline
$g_m = 0$ & Symmetric\\
$g_m > 0$ & Positive Skew\\
$g_m < 0$ & Negative Skew
\end{tabular}
\end{table}

\paragraph{Degree of Skewness}
The degree of skewness from the value is $g_m$ is:
\begin{table}[h!]
\begin{tabular}{c|c}
Value of $g_m$ & Degree\\
\hline
$|g_m| > 1$ & High Skewness\\
$0.5 <|g_m| \geq 1$ & Moderate Skewness\\
$|g_m| \leq 0.5$ & Low Skewness
\end{tabular}
\end{table}

\subsection{Kurtosis}
Kurtosis is the measure of peakedness of data. Fisher's kurtosis measure is defined as:
\begin{align}
\gamma &= \dfrac{m_4}{s^4}, \text{ where}\\
m_4 &= \dfrac{1}{n}\sum_{i=1}^{n} \left( x_i - \bar{x} \right)^4
\end{align}

\subsubsection{Type of Kurtosis}
The types of kurtosis from the value of $\gamma$ are:
\begin{table}[h!]
\begin{tabular}{c|c}
Value of $\gamma$ & Type\\
\hline
$\gamma = 0$ & Normal Distribution or Mesokurtic\\
$\gamma < 0$ & Flattened or Platykurtic\\
$\gamma > 0$ & Peaked or Lepokurtic
\end{tabular}
\end{table}

\section{Hypothesis Testing}
\subsection{T-Test}
\begin{align}
T = \dfrac{\bar{X}-\mu}{\frac{s}{\sqrt{n}}}
\end{align}
where:
\begin{align*}
\bar{X} &= \text{Sample Mean}\\
\mu &= \text{Assumed Mean}\\
s &= \text{Number of Samples}\\
n &= \text{Number of observations}
\end{align*}

If $T < t_c$ the $H_0$ is not rejected. $t_c$ is a functions of level of significance $(\alpha)$ and degrees of freedom $(v = n -1)$.

\subsection{$\chi^2$ Test}
\begin{align}
\chi^2 = \sum_i \sum_j \dfrac{(h_{ij}^o-h_{ij}^e)^2}{h_{ij}^e}
\end{align}
where:
\begin{align*}
h_e &= \text{Expected Value}\\
h_o &= \text{Actual Value}
\end{align*}

If $\chi^2 < \chi_c^2$ then $H_0$ is not rejected. $\chi_c$ is a functions of level of significance $(\alpha)$ and degrees of freedom $(v = (i-1)(j-1))$.

\section{Research and Survey Design}
\subsection{Population Covariance}
\begin{align}
\text{Cov}(x,y)=\dfrac{1}{n} \sum_{i=1}^n (x_i-\mu_x)(y_i-\mu_y)
\end{align}
\subsection{Sample Covariance}
\begin{align}
\text{Cov}(x,y)=\dfrac{1}{n-1} \sum_{i=1}^n (x_i-\bar{x})(y_i-\bar{y})
\end{align}
\subsection{Bravais-Pearson Correlation Co-efficient}
\begin{align}
r &= \dfrac{\sum_{i=1}^n (x_i-\bar{x})(y_i-\bar{y})}{\sqrt{\sum_{i=1}^n (x_i-\bar{x})^2} \cdot \sqrt{\sum_{i=1}^n (y_i -\bar{y})^2}}\\
& = \dfrac{\text{Cov}(x,y)}{\sqrt{\text{Var}(x) \cdot \text{Var}(y)}}\\
& = \dfrac{\text{Cov}(x,y)}{\sigma_x \cdot \sigma_y}
\end{align}

\section{Estimation of Regression Function}
For the regression functions:
\begin{align}
	Y_i = \beta_0 + \beta_1 X_1\\
	\hat{Y_i} = \hat{\beta_0} + \hat{\beta_1} X_1\\
\end{align}
where $Y_i$ is the observed dependent variable (DV), $\hat{Y_i}$ is the estimated DV, and $X_i$ is the independent variable (IV).
\begin{align}
	u_i &= Y_i - \hat{Y_i}\\
	\Rightarrow Y_i &= \hat{Y_i} + u_i\\
	\Rightarrow Y_i &= \hat{\beta_0} + \hat{\beta_1} X_1 + u_i
\end{align}

\end{document}
